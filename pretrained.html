<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="generator" content="ExDoc v0.28.0">
    <meta name="project" content="Tokenizers v0.1.2-dev">

    <title>Pretrained Tokenizers — Tokenizers v0.1.2-dev</title>
    <link rel="stylesheet" href="dist/elixir-a816d167216329cc463d.css" />

    <script src="dist/sidebar_items-a549e0dd25.js"></script>

      <script src="docs_config.js"></script>

    <script async src="dist/app-80aa23c1d96b6dc3c064.js"></script>


  </head>
  <body data-type="extras">
    <script>

      try {
        if (localStorage.getItem('night-mode') === 'true') {
          document.body.classList.add('night-mode');
        }
      } catch (error) { }
    </script>

<div class="main">


<section class="sidebar">
  <button class="sidebar-button sidebar-toggle">
    <i class="ri-menu-line ri-lg" title="Collapse/expand sidebar"></i>
  </button>

  <form class="sidebar-search" action="search.html">
    <button type="submit" class="search-button" aria-label="Submit Search">
      <i class="ri-search-2-line" aria-hidden="true" title="Submit search"></i>
    </button>
    <button type="button" tabindex="-1" class="search-close-button" aria-label="Cancel Search">
      <i class="ri-close-line ri-lg" aria-hidden="true" title="Cancel search"></i>
    </button>
    <label class="search-label">
      <input name="q" type="text" class="search-input" placeholder="Search..." aria-label="Input your search terms" autocomplete="off" />
    </label>
  </form>

  <div class="autocomplete">
    <div class="autocomplete-results">
    </div>
  </div>

  <div class="sidebar-header">

    <div class="sidebar-projectDetails">
      <a href="Tokenizers.html" class="sidebar-projectName" translate="no">
Tokenizers
      </a>
      <strong class="sidebar-projectVersion" translate="no">
        v0.1.2-dev
      </strong>
    </div>
    <ul class="sidebar-listNav">
      <li><a id="extras-list-link" href="#full-list">Pages</a></li>

        <li><a id="modules-list-link" href="#full-list">Modules</a></li>


    </ul>
  </div>

  <div class="gradient"></div>
  <ul id="full-list" class="sidebar-fullList"></ul>
</section>

<section class="content">
  <div class="content-outer">
    <div id="content" class="content-inner">

<h1>
<button class="settings display-settings">
  <i class="ri-settings-3-line"></i>
  <span class="sr-only">Settings</span>
</button>


    <a href="https://github.com/elixir-nx/tokenizers/blob/v0.1.2-dev/notebooks/pretrained.livemd#L1" title="View Source" class="view-source" rel="help">
      <i class="ri-code-s-slash-line" aria-hidden="true"></i>
      <span class="sr-only">View Source</span>
    </a>

  <span>Pretrained Tokenizers</span>
</h1>

  <div class="livebook-badge-container">
    <a href="#" class="livebook-badge">
      <img src="https://livebook.dev/badge/v1/blue.svg" alt="Run in Livebook" width="150" />
    </a>
  </div>

<h2 id="setup" class="section-heading">
  <a href="#setup" class="hover-link"><i class="ri-link-m" aria-hidden="true"></i></a>
  Setup
</h2>
<p>This Livebook will demonstrate how to use <a href="Tokenizers.html"><code class="inline">Tokenizers</code></a> with pretrained tokenizers available on the <a href="https://huggingface.co/models">Hugging Face Hub</a>.</p><p>We'll install <code class="inline">Kino</code> for user input and <code class="inline">SciData</code> for real data to tokenize.</p><pre><code class="makeup elixir" translate="no"><span class="nc">Mix</span><span class="o">.</span><span class="n">install</span><span class="p" data-group-id="6476743967-1">(</span><span class="w">
  </span><span class="p" data-group-id="6476743967-2">[</span><span class="w">
    </span><span class="p" data-group-id="6476743967-3">{</span><span class="ss">:kino</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;~&gt; 0.5.2&quot;</span><span class="p" data-group-id="6476743967-3">}</span><span class="p">,</span><span class="w">
    </span><span class="p" data-group-id="6476743967-4">{</span><span class="ss">:scidata</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;~&gt; 0.1.5&quot;</span><span class="p" data-group-id="6476743967-4">}</span><span class="p">,</span><span class="w">
    </span><span class="p" data-group-id="6476743967-5">{</span><span class="ss">:tokenizers</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;~&gt; 0.1.0&quot;</span><span class="p" data-group-id="6476743967-5">}</span><span class="p">,</span><span class="w">
    </span><span class="p" data-group-id="6476743967-6">{</span><span class="ss">:nx</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;~&gt; 0.3&quot;</span><span class="p" data-group-id="6476743967-6">}</span><span class="w">
  </span><span class="p" data-group-id="6476743967-2">]</span><span class="p">,</span><span class="w">
  </span><span class="ss">force</span><span class="p">:</span><span class="w"> </span><span class="no">true</span><span class="w">
</span><span class="p" data-group-id="6476743967-1">)</span></code></pre><p>We'll alias modules in <a href="Tokenizers.html"><code class="inline">Tokenizers</code></a> for readability. For now, the two main entry points into <a href="Tokenizers.html"><code class="inline">Tokenizers</code></a> are the <code class="inline">Tokenizer</code> and <code class="inline">Encoding</code> modules.</p><pre><code class="makeup elixir" translate="no"><span class="kn">alias</span><span class="w"> </span><span class="nc">Tokenizers.Tokenizer</span><span class="w">
</span><span class="kn">alias</span><span class="w"> </span><span class="nc">Tokenizers.Encoding</span></code></pre><h2 id="get-a-tokenizer" class="section-heading">
  <a href="#get-a-tokenizer" class="hover-link"><i class="ri-link-m" aria-hidden="true"></i></a>
  Get a tokenizer
</h2>
<p>The first thing to do is get a tokenizer from the hub. I've chosen <code class="inline">bert-base-cased</code> here as it's commonly used in Hugging Face examples. This call will download the tokenizer from the hub and load it into memory.</p><pre><code class="makeup elixir" translate="no"><span class="p" data-group-id="3249391280-1">{</span><span class="ss">:ok</span><span class="p">,</span><span class="w"> </span><span class="n">tokenizer</span><span class="p" data-group-id="3249391280-1">}</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nc">Tokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p" data-group-id="3249391280-2">(</span><span class="s">&quot;bert-base-cased&quot;</span><span class="p" data-group-id="3249391280-2">)</span></code></pre><h2 id="save-and-load" class="section-heading">
  <a href="#save-and-load" class="hover-link"><i class="ri-link-m" aria-hidden="true"></i></a>
  Save and load
</h2>
<p>You can save and load models. That means you can load in tokenizers you may have trained locally!</p><p>You can choose the path with the Kino input below.</p><pre><code class="makeup elixir" translate="no"><span class="n">input</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nc">Kino.Input</span><span class="o">.</span><span class="n">text</span><span class="p" data-group-id="5580407152-1">(</span><span class="s">&quot;Path&quot;</span><span class="p" data-group-id="5580407152-1">)</span></code></pre><pre><code class="makeup elixir" translate="no"><span class="n">path</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nc">Kino.Input</span><span class="o">.</span><span class="n">read</span><span class="p" data-group-id="5057389569-1">(</span><span class="n">input</span><span class="p" data-group-id="5057389569-1">)</span><span class="w">
</span><span class="nc">Tokenizer</span><span class="o">.</span><span class="n">save</span><span class="p" data-group-id="5057389569-2">(</span><span class="n">tokenizer</span><span class="p">,</span><span class="w"> </span><span class="n">path</span><span class="p" data-group-id="5057389569-2">)</span></code></pre><pre><code class="makeup elixir" translate="no"><span class="p" data-group-id="9771512150-1">{</span><span class="ss">:ok</span><span class="p">,</span><span class="w"> </span><span class="n">tokenizer</span><span class="p" data-group-id="9771512150-1">}</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nc">Tokenizer</span><span class="o">.</span><span class="n">from_file</span><span class="p" data-group-id="9771512150-2">(</span><span class="n">path</span><span class="p" data-group-id="9771512150-2">)</span></code></pre><h2 id="check-the-tokenizer" class="section-heading">
  <a href="#check-the-tokenizer" class="hover-link"><i class="ri-link-m" aria-hidden="true"></i></a>
  Check the tokenizer
</h2>
<p>Let's see what we can do with the tokenizer. First, let's have a look at the vocab. It's represented as a map of tokens to ids.</p><pre><code class="makeup elixir" translate="no"><span class="n">vocab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nc">Tokenizer</span><span class="o">.</span><span class="n">get_vocab</span><span class="p" data-group-id="9235194482-1">(</span><span class="n">tokenizer</span><span class="p" data-group-id="9235194482-1">)</span></code></pre><p>We can access an id using the vocab, but we don't need to extract the vocab. <code class="inline">Tokenizer.token_to_id/2</code> does the job for us.</p><pre><code class="makeup elixir" translate="no"><span class="n">vocab</span><span class="p" data-group-id="4949878023-1">[</span><span class="s">&quot;Jaguar&quot;</span><span class="p" data-group-id="4949878023-1">]</span></code></pre><pre><code class="makeup elixir" translate="no"><span class="nc">Tokenizer</span><span class="o">.</span><span class="n">token_to_id</span><span class="p" data-group-id="5169631567-1">(</span><span class="n">tokenizer</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;Jaguar&quot;</span><span class="p" data-group-id="5169631567-1">)</span></code></pre><p>And if we want to go back the other way...</p><pre><code class="makeup elixir" translate="no"><span class="nc">Tokenizer</span><span class="o">.</span><span class="n">id_to_token</span><span class="p" data-group-id="0605242605-1">(</span><span class="n">tokenizer</span><span class="p">,</span><span class="w"> </span><span class="mi">21694</span><span class="p" data-group-id="0605242605-1">)</span></code></pre><p>We can also see the vocab size.</p><pre><code class="makeup elixir" translate="no"><span class="nc">Tokenizer</span><span class="o">.</span><span class="n">get_vocab_size</span><span class="p" data-group-id="0984741309-1">(</span><span class="n">tokenizer</span><span class="p" data-group-id="0984741309-1">)</span></code></pre><h2 id="encode-and-decode" class="section-heading">
  <a href="#encode-and-decode" class="hover-link"><i class="ri-link-m" aria-hidden="true"></i></a>
  Encode and decode
</h2>
<p>When you tokenize some text you get an encoding. This is represented as <code class="inline">Tokenizers.Encoding.t()</code>. Because <a href="Tokenizers.html"><code class="inline">Tokenizers</code></a> relies on Rust bindings, the encoding itself appears opaque.</p><pre><code class="makeup elixir" translate="no"><span class="p" data-group-id="4060292755-1">{</span><span class="ss">:ok</span><span class="p">,</span><span class="w"> </span><span class="n">encoding</span><span class="p" data-group-id="4060292755-1">}</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nc">Tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p" data-group-id="4060292755-2">(</span><span class="n">tokenizer</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;Hello there!&quot;</span><span class="p" data-group-id="4060292755-2">)</span></code></pre><p>However, we can get the ids for the encoding as an Elixir list.</p><pre><code class="makeup elixir" translate="no"><span class="n">ids</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nc">Encoding</span><span class="o">.</span><span class="n">get_ids</span><span class="p" data-group-id="5960864061-1">(</span><span class="n">encoding</span><span class="p" data-group-id="5960864061-1">)</span></code></pre><p>And we can decode those back into tokens.</p><pre><code class="makeup elixir" translate="no"><span class="nc">Tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p" data-group-id="3729306407-1">(</span><span class="n">tokenizer</span><span class="p">,</span><span class="w"> </span><span class="n">ids</span><span class="p" data-group-id="3729306407-1">)</span></code></pre><p>Passing a batch of text as a list of strings returns a batch of encodings.</p><pre><code class="makeup elixir" translate="no"><span class="p" data-group-id="5125095529-1">{</span><span class="ss">:ok</span><span class="p">,</span><span class="w"> </span><span class="n">encodings</span><span class="p" data-group-id="5125095529-1">}</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nc">Tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p" data-group-id="5125095529-2">(</span><span class="n">tokenizer</span><span class="p">,</span><span class="w"> </span><span class="p" data-group-id="5125095529-3">[</span><span class="s">&quot;Hello there!&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;This is a test.&quot;</span><span class="p" data-group-id="5125095529-3">]</span><span class="p" data-group-id="5125095529-2">)</span></code></pre><p>And we can see the list of ids and decode them again.</p><pre><code class="makeup elixir" translate="no"><span class="n">list_of_ids</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nc">Enum</span><span class="o">.</span><span class="n">map</span><span class="p" data-group-id="7726330788-1">(</span><span class="n">encodings</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="nc">Encoding</span><span class="o">.</span><span class="n">get_ids</span><span class="o">/</span><span class="mi">1</span><span class="p" data-group-id="7726330788-1">)</span></code></pre><pre><code class="makeup elixir" translate="no"><span class="nc">Tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p" data-group-id="3492277447-1">(</span><span class="n">tokenizer</span><span class="p">,</span><span class="w"> </span><span class="n">list_of_ids</span><span class="p" data-group-id="3492277447-1">)</span></code></pre><h2 id="get-a-tensor" class="section-heading">
  <a href="#get-a-tensor" class="hover-link"><i class="ri-link-m" aria-hidden="true"></i></a>
  Get a tensor
</h2>
<p>Typically the reason we're tokenizing text is to use it as an input in a machine learning model. For that, we'll need tensors.</p><p>In order to get a tensor, we need sequences that are all of the same length. We'll get some data from <code class="inline">Scidata</code> and use <a href="Tokenizers.Encoding.html#pad/3"><code class="inline">Tokenizers.Encoding.pad/3</code></a> and <a href="Tokenizers.Encoding.html#truncate/3"><code class="inline">Tokenizers.Encoding.truncate/3</code></a> to yield a tensor.</p><pre><code class="makeup elixir" translate="no"><span class="p" data-group-id="5537271032-1">%{</span><span class="ss">review</span><span class="p">:</span><span class="w"> </span><span class="n">reviews</span><span class="p" data-group-id="5537271032-1">}</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nc">Scidata.YelpPolarityReviews</span><span class="o">.</span><span class="n">download_test</span><span class="p" data-group-id="5537271032-2">(</span><span class="p" data-group-id="5537271032-2">)</span></code></pre><pre><code class="makeup elixir" translate="no"><span class="n">tensor</span><span class="w"> </span><span class="o">=</span><span class="w">
  </span><span class="n">reviews</span><span class="w">
  </span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Enum</span><span class="o">.</span><span class="n">take</span><span class="p" data-group-id="0000622127-1">(</span><span class="mi">10</span><span class="p" data-group-id="0000622127-1">)</span><span class="w">
  </span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Enum</span><span class="o">.</span><span class="n">map</span><span class="p" data-group-id="0000622127-2">(</span><span class="k" data-group-id="0000622127-3">fn</span><span class="w"> </span><span class="n">review</span><span class="w"> </span><span class="o">-&gt;</span><span class="w">
    </span><span class="p" data-group-id="0000622127-4">{</span><span class="ss">:ok</span><span class="p">,</span><span class="w"> </span><span class="n">tokenized</span><span class="p" data-group-id="0000622127-4">}</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nc">Tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p" data-group-id="0000622127-5">(</span><span class="n">tokenizer</span><span class="p">,</span><span class="w"> </span><span class="n">review</span><span class="p" data-group-id="0000622127-5">)</span><span class="w">
    </span><span class="n">padded</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nc">Encoding</span><span class="o">.</span><span class="n">pad</span><span class="p" data-group-id="0000622127-6">(</span><span class="n">tokenized</span><span class="p">,</span><span class="w"> </span><span class="mi">200</span><span class="p" data-group-id="0000622127-6">)</span><span class="w">
    </span><span class="n">truncated</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nc">Encoding</span><span class="o">.</span><span class="n">truncate</span><span class="p" data-group-id="0000622127-7">(</span><span class="n">padded</span><span class="p">,</span><span class="w"> </span><span class="mi">200</span><span class="p" data-group-id="0000622127-7">)</span><span class="w">
    </span><span class="nc">Encoding</span><span class="o">.</span><span class="n">get_ids</span><span class="p" data-group-id="0000622127-8">(</span><span class="n">truncated</span><span class="p" data-group-id="0000622127-8">)</span><span class="w">
  </span><span class="k" data-group-id="0000622127-3">end</span><span class="p" data-group-id="0000622127-2">)</span><span class="w">
  </span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Nx</span><span class="o">.</span><span class="n">tensor</span><span class="p" data-group-id="0000622127-9">(</span><span class="p" data-group-id="0000622127-9">)</span></code></pre><p>And we can reverse the operation to see our data. Note the <code class="inline">[PAD]</code> tokens.</p><pre><code class="makeup elixir" translate="no"><span class="n">tensor</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Nx</span><span class="o">.</span><span class="n">to_batched_list</span><span class="p" data-group-id="9179617011-1">(</span><span class="mi">1</span><span class="p" data-group-id="9179617011-1">)</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Enum</span><span class="o">.</span><span class="n">map</span><span class="p" data-group-id="9179617011-2">(</span><span class="k" data-group-id="9179617011-3">fn</span><span class="w"> </span><span class="n">tensor_review</span><span class="w"> </span><span class="o">-&gt;</span><span class="w">
  </span><span class="p" data-group-id="9179617011-4">{</span><span class="ss">:ok</span><span class="p">,</span><span class="w"> </span><span class="n">decoded</span><span class="p" data-group-id="9179617011-4">}</span><span class="w"> </span><span class="o">=</span><span class="w">
    </span><span class="n">tensor_review</span><span class="w">
    </span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Nx</span><span class="o">.</span><span class="n">to_flat_list</span><span class="p" data-group-id="9179617011-5">(</span><span class="p" data-group-id="9179617011-5">)</span><span class="w">
    </span><span class="o">|&gt;</span><span class="w"> </span><span class="n">then</span><span class="p" data-group-id="9179617011-6">(</span><span class="o">&amp;</span><span class="nc">Tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p" data-group-id="9179617011-7">(</span><span class="n">tokenizer</span><span class="p">,</span><span class="w"> </span><span class="ni">&amp;1</span><span class="p" data-group-id="9179617011-7">)</span><span class="p" data-group-id="9179617011-6">)</span><span class="w">

  </span><span class="n">decoded</span><span class="w">
</span><span class="k" data-group-id="9179617011-3">end</span><span class="p" data-group-id="9179617011-2">)</span></code></pre>
<div class="bottom-actions">
  <div class="bottom-actions-item">

      <a href="license.html" class="bottom-actions-button" rel="prev">
        <span class="subheader">
          ← Previous Page
        </span>
        <span class="title">
LICENSE
        </span>
      </a>

  </div>
  <div class="bottom-actions-item">

  </div>
</div>

      <footer class="footer">

          <p>
            On Hex.pm:

            <span class="line">
              <a href="https://hex.pm/packages/tokenizers/0.1.2-dev" class="line footer-hex-package">Package</a>
              <a href="https://preview.hex.pm/preview/tokenizers/0.1.2-dev" class="line">Preview</a>

                <a href="https://preview.hex.pm/preview/tokenizers/0.1.2-dev/show/notebooks/pretrained.livemd">(current file)</a>

            </span>

            <button class="line footer-button display-quick-switch">
              Search
            </button>
          </p>

        <p>
          Built using
          <a href="https://github.com/elixir-lang/ex_doc" title="ExDoc" target="_blank" rel="help noopener" translate="no">ExDoc</a> (v0.28.0) for the
          <a href="https://elixir-lang.org" title="Elixir" target="_blank" translate="no">Elixir programming language</a>
        </p>
      </footer>
    </div>
  </div>
</section>
</div>


  </body>
</html>
