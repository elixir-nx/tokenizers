defmodule Tokenizers.Normalizer do
  @moduledoc """
  Normalizers and normalization functions.

  A normalizer is in charge of pre-processing the input string in
  order to normalize it as relevant for the given use case.

  Some common examples of normalization are the Unicode normalization
  algorithms (NFD, NFKD, NFC & NFKC) or lowercasing. The specificity
  of tokenizers is that we keep track of the alignment while
  normalizing. This is essential to allow mapping from the generated
  tokens back to the input text.
  """

  defstruct [:resource]

  @type t() :: %__MODULE__{resource: reference()}

  @doc """
  Normalizes the given text input.
  """
  @spec normalize(t(), String.t()) :: {:ok, String.t()}
  defdelegate normalize(normalizer, input), to: Tokenizers.Native, as: :normalizers_normalize

  @doc """
  Takes care of normalizing raw text before giving it to a BERT model.

  This includes cleaning the text, handling accents, Chinese chars and
  lowercasing.

  ## Options

    * `:clean_text` - whether to clean the text, by removing any
      control characters and replacing all whitespaces by the classic
      one. Defaults to `true`

    * `:handle_chinese_chars` - whether to handle chinese chars by
      putting spaces around them. Default `true`

    * `:strip_accents` - whether to strip all accents. If this option
      is not specified, then it will be determined by the value for
      lowercase (as in the original Bert)

    * `:lowercase` - whether to lowercase. Default `true`

  """
  @spec bert_normalizer(keyword()) :: t()
  defdelegate bert_normalizer(opts \\ []),
    to: Tokenizers.Native,
    as: :normalizers_bert_normalizer

  @doc """
  Creates a NFD Unicode normalizer.
  """
  @spec nfd :: t()
  defdelegate nfd(), to: Tokenizers.Native, as: :normalizers_nfd

  @doc """
  Creates a NFKD Unicode normalizer.
  """
  @spec nfkd :: t()
  defdelegate nfkd(), to: Tokenizers.Native, as: :normalizers_nfkd

  @doc """
  Creates a NFC Unicode normalizer.
  """
  @spec nfc :: t()
  defdelegate nfc(), to: Tokenizers.Native, as: :normalizers_nfc

  @doc """
  Creates a NFKC Unicode normalizer.
  """
  @spec nfkc :: t()
  defdelegate nfkc(), to: Tokenizers.Native, as: :normalizers_nfkc

  @doc """
  Creates a Strip normalizer.

  Removes all whitespace characters on the specified sides (left,
  right or both) of the input

  ## Options

    * `:left` - whether to strip left side. Defaults to `true`

    * `:right` - whether to strip right side. Defaults to `true`

  """
  @spec strip(keyword()) :: t()
  defdelegate strip(opts \\ []), to: Tokenizers.Native, as: :normalizers_strip

  @doc """
  Creates a Prepend normalizer.
  """
  @spec prepend(prepend :: String.t()) :: t()
  defdelegate prepend(prepend), to: Tokenizers.Native, as: :normalizers_prepend

  @doc """
  Creates a Strip Accent normalizer.

  Removes all accent symbols in unicode (to be used with NFD for
  consistency).
  """
  @spec strip_accents :: t()
  defdelegate strip_accents(), to: Tokenizers.Native, as: :normalizers_strip_accents

  @doc """
  Composes multiple normalizers that will run in the provided order.
  """
  @spec sequence([t()]) :: t()
  defdelegate sequence(normalizers), to: Tokenizers.Native, as: :normalizers_sequence

  @doc """
  Replaces all uppercase to lowercase
  """
  @spec lowercase :: t()
  defdelegate lowercase(), to: Tokenizers.Native, as: :normalizers_lowercase

  @doc """
  Replaces a custom `search` string with the given `content`.
  """
  @spec replace(String.t(), String.t()) :: t()
  def replace(search, content) do
    Tokenizers.Native.normalizers_replace({:string, search}, content)
  end

  @doc """
  Replaces occurrences of a custom regexp `pattern` with the given `content`.

  The `pattern` should be a string representing a regular expression
  according to the [Oniguruma Regex Engine](https://github.com/kkos/oniguruma).
  """
  @spec replace_regex(String.t(), String.t()) :: t()
  def replace_regex(pattern, content) do
    Tokenizers.Native.normalizers_replace({:regex, pattern}, content)
  end

  @doc """
  Creates a Nmt normalizer.
  """
  @spec nmt :: t()
  defdelegate nmt(), to: Tokenizers.Native, as: :normalizers_nmt

  @doc """
  Precompiled normalizer.

  Donâ€™t use manually it is used for compatibility with SentencePiece.
  """
  @spec precompiled(binary()) :: {:ok, t()} | {:error, any()}
  defdelegate precompiled(data), to: Tokenizers.Native, as: :normalizers_precompiled
end

defimpl Inspect, for: Tokenizers.Normalizer do
  import Inspect.Algebra

  def inspect(decoder, opts) do
    attrs =
      decoder
      |> Tokenizers.Native.normalizers_info()
      |> Keyword.new(fn {k, v} -> {String.to_atom(k), v} end)

    concat(["#Tokenizers.Normalizer<", to_doc(attrs, opts), ">"])
  end
end
